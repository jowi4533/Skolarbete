{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\"CNN Classification on handwritten digits(images) with noise \"\"\"\n",
    "\"\"\"Assignment 4 done by Jonas Wikstr√∂m\"\"\"\n",
    "#imports!\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data set\n",
    "train = pd.read_csv(\"data/trainset.csv\") \n",
    "X_real_test = pd.read_csv(\"data/testset.csv\")\n",
    "#train = train[0:1000]\n",
    "#train, test = train_test_split(train, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Creates a 28x28 matrix instead of a 784 row (Test Data) \"\"\"\n",
    "def handleTestData(data):\n",
    "    testing_data = []\n",
    "    for index, row in data.iterrows():\n",
    "        pxl_list = []\n",
    "        for i in range(28):\n",
    "            x = 28\n",
    "            one_row = row[(i*x):((i+1)*x)].values\n",
    "            pxl_list.append(one_row)\n",
    "        testing_data.append([pxl_list])\n",
    "    return(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14000, 28, 28, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"#about real testing data\"\"\"\"\n",
    "testing_data = handleTestData(X_real_test)\n",
    "real_test_data = np.array(testing_data).reshape(-1,28,28,1) \n",
    "real_test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"Creates a 28x28 matrix instead of a 784 row and save it with corresponding label (Training data)\"\"\"\n",
    "def createImages(data):\n",
    "    training_data = []\n",
    "    x = 28\n",
    "    for index, row in data.iterrows():\n",
    "        pxl_list = []\n",
    "        label = row.iloc[0]\n",
    "        for i in range(28):\n",
    "            one_row = row[(i*x+1):((i+1)*x+1)].values\n",
    "            pxl_list.append(one_row)\n",
    "        training_data.append([label,pxl_list])\n",
    "    return(training_data)   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Prepair training data\"\"\"\n",
    "training_data = createImages(train)\n",
    "X_train = []\n",
    "Y_train = []\n",
    "img_size = 28\n",
    "for label,image in training_data:\n",
    "    Y_train.append(label)\n",
    "    X_train.append(image)\n",
    "    \n",
    "Y_train = np.array(Y_train)\n",
    "X_train = np.array(X_train).reshape(-1,img_size,img_size,1)\n",
    "\n",
    "#make class vectors, 10 different classes \n",
    "Y_train = keras.utils.to_categorical(Y_train, 10)\n",
    "X_train = X_train.astype('float32')\n",
    "X_train /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'createImages' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-142703766b89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreateImages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mimg_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'createImages' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This block is not used at the moment \n",
    "Just used it for validating the performance of the model\n",
    "\"\"\"\n",
    "\n",
    "X_test = []\n",
    "Y_test = []\n",
    "test_data = createImages(test)\n",
    "img_size = 28\n",
    "for label,image in test_data:\n",
    "    Y_test.append(label)\n",
    "    X_test.append(image)\n",
    "    \n",
    "Y_test = np.array(Y_test)\n",
    "X_test = np.array(X_test).reshape(-1,img_size,img_size,1)\n",
    "Y_test = keras.utils.to_categorical(Y_test, 10)\n",
    "X_test = X_test.astype('float32')\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "(28000, 28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"Just prints to get an idea of output \"\"\"\n",
    "\n",
    "plt.imshow(training_data[155][1], cmap = \"gray\")\n",
    "print(training_data[155][0])\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28000 samples\n",
      "Epoch 1/15\n",
      "28000/28000 [==============================] - 49s 2ms/sample - loss: 0.7324 - accuracy: 0.7587\n",
      "Epoch 2/15\n",
      "28000/28000 [==============================] - 59s 2ms/sample - loss: 0.3543 - accuracy: 0.8867\n",
      "Epoch 3/15\n",
      "28000/28000 [==============================] - 57s 2ms/sample - loss: 0.2748 - accuracy: 0.9108\n",
      "Epoch 4/15\n",
      "28000/28000 [==============================] - 54s 2ms/sample - loss: 0.2328 - accuracy: 0.9258\n",
      "Epoch 5/15\n",
      "28000/28000 [==============================] - 50s 2ms/sample - loss: 0.2101 - accuracy: 0.9307\n",
      "Epoch 6/15\n",
      " 4400/28000 [===>..........................] - ETA: 40s - loss: 0.1711 - accuracy: 0.9430"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-1d069758749d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m model.fit(x=X_train, y=Y_train, \n\u001b[1;32m     25\u001b[0m          \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m           epochs = 15);\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\" I construct the CNN \n",
    "Use model.summary() to see the structure of the network\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def makeModel():\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(32, kernel_size=(2, 2), activation='relu',\n",
    "                              input_shape=(28,28,1)))\n",
    "    model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "model  =  makeModel()\n",
    "model.fit(x=X_train, y=Y_train, \n",
    "         batch_size = 50, \n",
    "          epochs = 15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                589888    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 609,354\n",
      "Trainable params: 609,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"We make the predictions and save them to a csv file \"\"\"\n",
    "index_list = X_real_test.index.tolist()\n",
    "index_list = [x+1 for x in index_list]\n",
    "ynew = model.predict_classes(real_test_data)\n",
    "pred_df = pd.DataFrame(list(zip(index_list,ynew)), \n",
    "               columns =['ImageID', 'Label'])\n",
    "pred_df.to_csv('samplesubmission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
